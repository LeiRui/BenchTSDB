
# IOTDB, INFLUXDB, TIMESCALEDB, KAIROSDB
# SUMMARYSTORE, WATERWHEEL, TSFILE, PARQUET, ORC
#DATABASE=IOTDB
DATABASE=INFLUXDB
#DATABASE=TIMESCALEDB
#DATABASE=KAIROSDB

# OPENTSDB_URL=http://127.0.0.1:4242
SUMMARYSTORE_PATH=sstore

# for IoTDB v0.14.0-snapshot (NonAlignedTablet分支)
IOTDB_HOST=127.0.0.1
IOTDB_PORT=6667
IOTDB_USERNAME=root
IOTDB_PASSWORD=root
IOTDB_ENABLE_THRIFT_COMPRESSION = false
# 每次运行会先删除这个存储组再重新创建
# for yanchang dataset
#IOTDB_STORAGE_GROUP = root.T000100010002
# for dianchang dataset
IOTDB_STORAGE_GROUP = root.DianChang

# for InfluxDB v1.8.10
INFLUXDB_URL=http://127.0.0.1:8086
# for yanchang dataset
#INFLUXDB_DATABASE=yanchang
# for dianchang dataset
INFLUXDB_DATABASE=dianchang

# for TimescaleDB v2.6.1 on RDBMS PostgreSQL v14.3
TIMESCALEDB_HOST=127.0.0.1
TIMESCALEDB_PORT=5432
TIMESCALEDB_USERNAME=postgres
TIMESCALEDB_PASSWORD=123
TIMESCALEDB_DATABASE=yanchang

# for KairosDB v1.3.0 on NoSQL database Cassandra v3.11.13
KAIROSDB_URL=http://127.0.0.1:8080
# TRUE to make points of a sensor batched, FALSE to make points totally separated.
#KAIROSDB_BATCH_POINTS=true
#CASSANDRA_IP=127.0.0.1
#CASSANDRA_PORT=9042

# 将所有数据写入此文件，查询也从这个文件查
FILE_PATH=test.file

## WaterWheelManager
#LOCAL=true
#WATERWHEEL_IP=127.0.0.1
#HDFS_IP=hdfs://127.0.0.1:9000
#WATERWHEEL_INGEST_PORT=10000
#WATERWHEEL_QUERY_PORT=10001


# NOAA, GEOLIFE, TDRIVE, MLAB_IP, MLAB_UTILIZATION, REDD, SYNTHETIC
DATA_SET=CSV
#DATA_DIR=data/yanchang
DATA_DIR=data/dianchang
# Only load files numbered in [BEGIN_FILE, END_FILE] under DATA_DIR.
# Number starts from 0.
# Not setting BEGIN_FILE and END_FILE means loading all files under DATA_DIR.
#BEGIN_FILE=0
#END_FILE=0

# true代表有现成的数据类型信息如下，false代表需要程序自动推断类型
TYPE_INFO_EXIST = true
# 数据类型文件地址，默认单个文件，默认用逗号分隔
## for yanchang dataset
#TYPE_INFO_FILE = data/yanchang_show_timeseries.csv
## 从0开始，序列名字的列号。序列名字默认与数据文件的header是同一种格式。
#TYPE_INFO_SERIES_COL = 1
## 从0开始，序列类型的列号
#TYPE_INFO_TYPE_COL = 4
## true代表有header，false代表没有
#TYPE_INFO_HEADER = true

# for dianchang dataset
TYPE_INFO_FILE = data/dianchang_data_type.csv
# 从0开始，序列名字的列号。序列名字默认与数据文件的header是同一种格式。
TYPE_INFO_SERIES_COL = 0
# 从0开始，序列类型的列号
TYPE_INFO_TYPE_COL = 1
# true代表有header，false代表没有
TYPE_INFO_HEADER = true


INFER_TYPE_MAX_RECORD_NUM = 10
split_file_by_device=false

synthetic_null_ratio=0.2
synthetic_device_num=10000
synthetic_measurement_num=100
synthetic_point_num=100

csv_separator=,

THREAD_NUM=10
BATCH_SIZE=1000

# TsFile configs
use_aligned_tablet=true

use_aligned_series=false

# for query

#QUERY_TYPE=SINGLE_SERIES_RAW_QUERY
##QUERY_PARAM=1
##QUERY_PARAM=100
##QUERY_PARAM=10000
#QUERY_PARAM=1000000

#QUERY_TYPE=MULTI_SERIES_ALIGN_QUERY
#QUERY_PARAM=1
#QUERY_PARAM=10
##QUERY_PARAM=100
#QUERY_PARAM=1000

#QUERY_TYPE=SINGLE_SERIES_COUNT_QUERY
##QUERY_PARAM=1
###QUERY_PARAM=100
###QUERY_PARAM=10000
#QUERY_PARAM=1000000

QUERY_TYPE=SINGLE_SERIES_DOWNSAMPLING_QUERY
#QUERY_PARAM=1000000
QUERY_PARAM=10000
#QUERY_PARAM=100
#QUERY_PARAM=1

# deviceID
# NOAA: root.group_0.d_033110_99999
# Geolife：root.group_0.d_000
# Redd: root.group_0.d_house_1_channel_1
# tdrive：root.group_0.d_1
# yanchang: root.T000100010002.90003
#QUERY_TAG=root.T000100010002.90003

# sensor
# NOAA: MAX
# Geolife：Latitude
# Redd: value
# tdrive：longitude
# yanchang: collecttime
#QUERY_FIELD=collecttime

#QUERY_START_TIME=min
#QUERY_END_TIME=max